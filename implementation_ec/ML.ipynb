{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.common import flatten\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import glob\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get file paths for train, test, and val images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to get file paths so we can create Custom Dataset Class\n",
    "\n",
    "train_data_path = 'Dataset/train' \n",
    "valid_data_path = 'Dataset/valid'\n",
    "test_data_path = 'Dataset/test'\n",
    "\n",
    "classes = [] \n",
    "\n",
    "# get train file paths\n",
    "train_image_paths = [] \n",
    "for data_path in glob.glob(train_data_path + '/*'): # gets all file paths recursively in train directory \n",
    "    classes.append(data_path.split('/')[-1])    # e.g. Dataset_2/train/antelope/fasdfdsaf.jpg -> antelope\n",
    "    train_image_paths.append(glob.glob(data_path + '/*'))   # append file path \n",
    "    \n",
    "train_image_paths = list(flatten(train_image_paths))    # flatten list \n",
    "\n",
    "# now valid\n",
    "valid_image_paths = [] \n",
    "for data_path in glob.glob(valid_data_path + '/*'):\n",
    "    valid_image_paths.append(glob.glob(data_path + '/*'))\n",
    "valid_image_paths = list(flatten(valid_image_paths))\n",
    "\n",
    "# now test\n",
    "test_image_paths = []\n",
    "for data_path in glob.glob(test_data_path + '/*'):\n",
    "    test_image_paths.append(glob.glob(data_path + '/*'))\n",
    "test_image_paths = list(flatten(test_image_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we cannot use strings, map class names to indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map an index to a class name\n",
    "idx_to_class = {i:j for i, j in enumerate(classes)}\n",
    "\n",
    "# Map a class name to an index (simply reverse key value pair of idx_to_class)\n",
    "class_to_idx = {value:key for key,value in idx_to_class.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement custom dataset class in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom Dataset class\n",
    "# need to implement __init__, __len__, and __getitem__\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=False):\n",
    "        self.image_paths = image_paths\n",
    "        # transforms were done using RoboFlow\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        label = image_filepath.split('/')[-2]   # gets the class of the image from the filepath\n",
    "        label = class_to_idx[label]     # converts to idx\n",
    "        \n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_image_paths)\n",
    "valid_dataset = Dataset(valid_image_paths) \n",
    "test_dataset = Dataset(test_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create out Classification model using 2D CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=90):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # 5 Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling for generalization\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # FC layers for flattening to 1d space\n",
    "        self.fc1 = nn.Linear(512 * 20 * 20, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "        \n",
    "        # Use ReLU as activation function, very common for deep learning\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = self.pool(self.relu(self.conv4(x)))\n",
    "        x = self.pool(self.relu(self.conv5(x)))\n",
    "        #print(x.shape) -> conv5 out shape is (512, 20, 20)\n",
    "        \n",
    "        # Flatten the output for fully connected layers\n",
    "        x = x.reshape(-1, 512 * 20 * 20) \n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, test, and validate\n",
    "\n",
    "This process is way too slow on my macbook air, but this is an example for how the model would be implemented. Likely would need more than 5 layers to have good classification accuracy, but this is more a proof of concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()   # good for classification models\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)    # Adam allows for dynamic lr \n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:        \n",
    "        inputs = inputs.type(torch.FloatTensor).permute(0, 3, 1, 2) # B x H x W x C -> B x C x H x W\n",
    "\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get output and compute loss, backpropogate\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # track loss and correct predictions\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # calculate train loss and accuracy\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:            \n",
    "            inputs = inputs.type(torch.FloatTensor).permute(0, 3, 1, 2) # B x H x W x C -> B x C x H x W\n",
    "\n",
    "            # no backprop needed\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_loss = running_loss / len(test_loader)\n",
    "    test_acc = 100. * correct / total\n",
    "    return test_loss, test_acc\n",
    "\n",
    "# Function to perform validation\n",
    "def validate(model, valid_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs = inputs.type(torch.FloatTensor).permute(0, 3, 1, 2) # B x H x W x C -> B x C x H x W\n",
    "\n",
    "            # no backprop needed\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    valid_loss = running_loss / len(valid_loader)\n",
    "    valid_acc = 100. * correct / total\n",
    "    return valid_loss, valid_acc\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 1    # good starting point for computer vision tasks\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    break   # takes extremely long time to run, my computer is not powerful enough\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
    "    valid_loss, valid_acc = validate(model, valid_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"Train Loss: {train_loss:.2f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.2f} | Test Acc: {test_acc:.2f}%\")\n",
    "    print(f\"Validation Loss: {valid_loss:.2f} | Validation Acc: {valid_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
